{
  "hash": "273473d5bef36e3f1db0c47b8ed20667",
  "result": {
    "markdown": "---\ntitle: \"Análise de Regressão\"\nauthor: \"Nívia\"\nformat: html\n---\n\n\n# Dados quantitativos e o uso de análise de regressão\n\nQuando se tem dados quantitativos, a análise de regressão é geralmente mais apropriada do que a análise de variância (ANOVA), pois a análise de regressão permite modelar e prever a relação entre uma variável dependente (Y) e uma ou mais variáveis independentes (X). Ela busca estimar os parâmetros de uma equação de regressão que descreve a relação funcional entre as variáveis. A análise de regressão pode fornecer informações sobre a direção e magnitude do efeito das variáveis independentes na variável dependente, bem como previsões ou estimativas para valores não observados.\n\n## Regressão linear simples\n\nNa análise de regressão linear, assume-se que a relação entre a variável dependente e a variável independente é linear, ou seja, pode ser descrita por uma linha reta. A equação da regressão linear é dada por: y = β0 + β1x + ε, onde\\>: y é a variável dependente (variável resposta), x é a variável independente (tratamento), β0 é o intercepto (ou constante) da equação de regressão, β1 é o coeficiente de inclinação (slope) da equação de regressão e ε é o erro aleatório.\n\nNa regressão linear simples, testamos a hipótese de que a reta de regressão (linha de melhor ajuste), que representa a relação entre as variáveis independentes e a variável dependente, tem um coeficiente de inclinação diferente de zero. Ou seja, testamos a hipótese de que a inclinação da reta de regressão é significativamente diferente de zero (testa se o p valor é diferente de 0).\n\n**Preparo pré-análise**:\n\n\n::: {.cell hash='Aula13_cache/html/unnamed-chunk-1_6884a61139a8c8257de53890350eefe5'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\n```\n:::\n\n\nConjunto de dados estande (dados-diversos): Visualização em ggplot Para ajustar para uma regressão linear usa-se o argumento method = \"lm\" dentro da função geom_smooth.\n\n\n::: {.cell hash='Aula13_cache/html/unnamed-chunk-2_5a1778fd4f9f3a90ef73fe11b861941d'}\n\n```{.r .cell-code}\nestande <- read_excel(\"dados-diversos.xlsx\", \"estande\")\nestande |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  facet_wrap(~ exp)+\n  geom_smooth(se =  F, method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n### Modelo de melhor ajuste\n\nPosteriomente, deve-se testar o modelo que melhor se ajusta aos dados.Pode-se testar fazer a análise de regressão para cada experimento (isola cada experimento) ou analisar em grupos (modelos mistos).\n\n***Analisando cada experimento isoladamente*** Para isso, cria um novo objeto para os dados (exp1) e atribui estande a ele, depois deve-se filtrar o experimento que deseja e criar um objeto para esse conjunto para viabilizar a realização da análise de regressão.\n\nExp 1:\n\n\n::: {.cell hash='Aula13_cache/html/unnamed-chunk-3_a5d55a3532492da39578a1bebe24c0ae'}\n\n```{.r .cell-code}\nexp1 <- estande |>\n  filter(exp == 1)\n\nm1 <- lm(nplants ~trat, data = exp1)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,\tAdjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n```\n:::\n:::\n\n\nO valor do intercept e o valor de trat (slope) são utilizados na tabela. Intercept é o valor da variável dependente quando a variável independente é igual a zero. Já o slope é a medida da inclinação da linha de regressão, que representa a mudança na variável dependente associada a uma mudança na variável independente.\n\nPara o experimento 2:\n\n\n::: {.cell hash='Aula13_cache/html/unnamed-chunk-4_65c1d3f0ba558dea4a76f637018671c7'}\n\n```{.r .cell-code}\nexp2 <- estande |>\n  filter(exp == 2)\n\nm2 <- lm(nplants ~trat, data = exp2)\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n:::\n:::\n\n\nPara o exp3:\n\n\n::: {.cell hash='Aula13_cache/html/unnamed-chunk-5_1a95b2eac57084750163442dd1bb6522'}\n\n```{.r .cell-code}\nexp3 <- estande |>\n  filter(exp == 3)\n\nm3 <- lm(nplants ~trat, data = exp3)\nsummary(m3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,\tAdjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n```\n:::\n\n```{.r .cell-code}\nlibrary(report)\nreport(m3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict nplants with trat\n(formula: nplants ~ trat). The model explains a statistically significant and\nsubstantial proportion of variance (R2 = 0.61, F(1, 22) = 34.19, p < .001, adj.\nR2 = 0.59). The model's intercept, corresponding to trat = 0, is at 95.75 (95%\nCI [89.63, 101.87], t(22) = 32.43, p < .001). Within this model:\n\n  - The effect of trat is statistically significant and negative (beta = -0.76,\n95% CI [-1.03, -0.49], t(22) = -5.85, p < .001; Std. beta = -0.78, 95% CI\n[-1.06, -0.50])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n```\n:::\n:::\n\n\nGráfico para representar a regressão - Para unir os 3 graficos, usa o patchwork.\n\n\n::: {.cell hash='Aula13_cache/html/unnamed-chunk-6_126a7fe9d8bce1742f1f41bdbaff9d1f'}\n\n```{.r .cell-code}\ng1 <- exp1 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = F)+\n  annotate(geom = \"text\", x = 24,\n           y = 70, label = \"y = 52.5 - 0.24x\")\n\ng2 <- exp2 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = F)+\n  annotate(geom = \"text\", x = 24,\n           y = 70, label = \"y = 60 - 0.07x\")\ng3 <- exp3 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = F)+\n  annotate(geom = \"text\", x = 24,\n           y = 70, label = \"y = 95 - 0.07x\")\n\nlibrary(patchwork)\ng1|g2|g3\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n## Modelo misto\n\nEm um modelo misto, as observações são divididas em grupos ou subgrupos. Cada grupo pode ter um conjunto diferente de efeitos aleatórios e/ou fixos, dependendo da estrutura dos dados. Por exemplo, se os dados foram coletados em diferentes locais geográficos, podemos ter um efeito aleatório para cada local (como no caso do conjunto de dados estande).\n\nEquação: b1 - b2x - cx2\n\n\n::: {.cell hash='Aula13_cache/html/unnamed-chunk-7_27f7ade991cbefd6a66478714f7d1df5'}\n\n```{.r .cell-code}\nlibrary(lme4)\nmix <- lmer(nplants ~trat + (trat | exp),\n            data = estande)\nsummary(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\nlibrary(car)\nAnova(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: nplants\n      Chisq Df Pr(>Chisq)    \ntrat 11.985  1  0.0005362 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nQuando se usa o modelo misto, considera que todos os experimentos são agrupados, então considera que amostra é aleatória. Para fazer o modelo de regressão em grupo (misto) acrescenta-se na função aestetic o argumento group = exp.\n\n\n::: {.cell hash='Aula13_cache/html/unnamed-chunk-8_175813ff7aac66b6f38e8e4f9e17fdef'}\n\n```{.r .cell-code}\nestande <- read_excel(\"dados-diversos.xlsx\", \"estande\")\nestande |>\n  ggplot(aes(trat, nplants, group = exp))+\n  geom_point()+\n  #facet_wrap(~ exp)+\n  geom_smooth(se =  F, method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](Aula13_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nEm geral, os modelos mistos são mais poderosos do que os modelos que tratam cada experimento isoladamente, pois levam em conta a variação tanto entre quanto dentro dos experimentos. Além disso, os modelos mistos permitem que os dados sejam analisados em sua totalidade, sem perder informações importantes sobre a estrutura dos dados.\n\n## Modelo GLM\n\nO modelo linear generalizado é uma alternativa ao modelo linear. O GLM é considerado uma extensão do modelo linear que permite acomodar uma variedade de tipos de variáveis resposta, incluindo variáveis categóricas e contínuas. Além disso, o modelo linear generalizado permite que a relação entre a variável resposta e as variáveis explicativas seja não-linear. Ou seja, ele não se limita à suposição de que a relação é uma linha reta.\n\n\n::: {.cell hash='Aula13_cache/html/unnamed-chunk-9_9582ac856e5311da46a70b01f0087c5f'}\n\n```{.r .cell-code}\nlm1 <- lm(nplants ~ trat, data = exp3)\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,\tAdjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n```\n:::\n\n```{.r .cell-code}\nglm1 <- glm(nplants ~ trat, family = \"gaussian\",\n            data = exp3)\n\nglm2 <- glm(nplants ~ trat, family = poisson(link = \"log\"),\n            data = exp3)\nAIC(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 185.0449\n```\n:::\n\n```{.r .cell-code}\nAIC(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 183.9324\n```\n:::\n\n```{.r .cell-code}\nsummary(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-26.5887   -3.9597    0.7177    5.5806   19.8952  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n```\n:::\n\n```{.r .cell-code}\nsummary(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-2.94600  -0.46988   0.02453   0.61868   2.34657  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\nO modelo linear generalizado com distribuição gaussiana (family = gaussian) é usado quando a variável resposta é contínua e tem uma distribuição normal, ou seja, o mesmo que \"lm\". Já o modelo linear generalizado com distribuição de Poisson é usado quando a variável resposta é um número inteiro e não negativo e segue uma distribuição de Poisson (family = poisson). O AIC (Akaike's Information Criterion) é um critério de seleção de modelo usado para escolher o melhor modelo entre vários modelos candidatos. A escolha do modelo com o menor AIC é importante porque ele é uma medida de qualidade do modelo que leva em consideração tanto o ajuste aos dados quanto a complexidade do modelo. Como o AIC de menor valor é melhor, a família poisson é o ideal para os dados analisados.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}