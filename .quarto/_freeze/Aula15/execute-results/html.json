{
  "hash": "dcf2dd69359315d638efc5e98ee60119",
  "result": {
    "markdown": "---\ntitle: \"Tabela de contingência e AUDPC\"\nauthor: \"Nívia\"\nformat: html\n---\n\n\n# Variáveis categóricas e tabelas de contingência\n\nNo caso de variáveis resposta categóricas, não se tira a média dos dados, ao invés disso, se monta uma tabela de contigência. As tabelas são usadas para resumir e apresentar a distribuição conjunta de duas ou mais variáveis categóricas. Elas são muito úteis para analisar a relação entre essas variáveis e identificar possíveis associações ou dependências.\n\nAs tabelas de contingência são bastante utilizadas em estatística descritiva, análise exploratória de dados e testes de associação, como o teste qui-quadrado. Essas tabelas de contingência podem ser visualizadas por meio de gráfico de barras/colunas, pois é melhor para a compreensão da distribuição conjunta das variáveis, se visualiza a frequência de ocorrências, quando se tem variáveis categóricas nominais.\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-1_5861711ce0c8f2e22ae5a04055df5db6'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(janitor)\nlibrary(epifitter)\n```\n:::\n\n\n*Função table()*: Essa função é utilizada para criar a tabela de contingência. A tabela é construída a partir das variáveis residue e species (pertencentes ao objeto survey. A função table() conta o número de ocorrências de cada combinação de categorias dessas variáveis e armazena os resultados na variável q.\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-2_18e1f39f83dab2b77748c714190e47b8'}\n\n```{.r .cell-code}\nsurvey <- read_excel(\"dados-diversos.xlsx\",\"survey\")\nsurvey |>\n  count(year)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n   year     n\n  <dbl> <int>\n1  2009   265\n2  2010   216\n3  2011   185\n```\n:::\n\n```{.r .cell-code}\nq <- table(survey$residue, survey$species)\n```\n:::\n\n\n*Pacote janitor*: O pacote janitor fornece funções úteis para limpeza e organização de dados, como: renomear colunas, remover valores ausentes, formatar dados em uma estrutura tabular, etc. Para dar os valores em porcentagem usa-se a função adorn_percentages(). A função tabyl() cria uma tabela de frequência tabular, mostrando a contagem de ocorrências de diferentes combinações de valores em variáveis categóricas.\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-3_f643d10c3729637d480f88ade35e8420'}\n\n```{.r .cell-code}\n#library(janitor)\nsurvey |>\n  tabyl(year, species)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n year Fgra Fspp\n 2009  225   40\n 2010  187   29\n 2011  140   45\n```\n:::\n:::\n\n\n**Visualizando os dados**:\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-4_474af174dd1601a04f7bb02f460a414b'}\n\n```{.r .cell-code}\nsurvey |>\n  filter(residue != \"NA\") |>\n  count(residue, species) |>\n  ggplot(aes(residue, n, fill = species))+\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](Aula15_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Teste qui-quadrado\n\nO teste qui-quadrado é utilizado para avaliar a associação entre duas variáveis categóricas e quando queremos determinar se existe uma associação significativa entre elas. Este teste é baseado na comparação das frequências observadas em uma tabela de contingência com as frequências esperadas sob a hipótese nula de independência entre as variáveis. Esse teste é realizado usando a função chisq.test(), que faz parte do pacote base do R.\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-5_c309d48cd0b43bdfff99e8d7d1a2557e'}\n\n```{.r .cell-code}\nq <- table(survey$residue, survey$species)\nchisq.test(q)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  q\nX-squared = 1.1997, df = 1, p-value = 0.2734\n```\n:::\n:::\n\n\nHipótese nula: as populações são iguais.\n\nFunção fisher.test(): Este teste é usado para avaliar a associação entre duas variáveis categóricas em uma tabela de contingência 2x2, ou seja, usa-se esta função quando o número de observações é baixo, algo em torno de 6 ou 7.\n\n**A severidade é influenciada pelo resíduo**?\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-6_1402aada1606f76632a0c164ad65db49'}\n\n```{.r .cell-code}\nq <- table(survey$residue, survey$inc_class)\nchisq.test(q)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  q\nX-squared = 2.6165, df = 1, p-value = 0.1058\n```\n:::\n\n```{.r .cell-code}\nsurvey|>\n  filter(residue != \"NA\") |>\n  count(residue, inc_class) |>\n  ggplot(aes(residue, n, fill = inc_class))+\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](Aula15_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n*Conclusão*: Pelo p valor, a classe de severidade independe do resto cultural, ou seja, o resto cultural não influencia na severidade.\n\nNovo conjunto de dados:\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-7_813d2c0aeb7e1700c18bed5ad849989b'}\n\n```{.r .cell-code}\ncurve <- read_excel(\"dados-diversos.xlsx\", \"curve\")\n\ncurve2 <- curve |> \n  group_by(Irrigation, day) |>\n  summarize(mean_severity = mean(severity),\n            sd_severity = sd(severity))\n\n  curve2 |>\n    ggplot(aes(day, mean_severity, color = Irrigation))+\n    geom_point()+\n    geom_errorbar(aes(ymin = mean_severity - sd_severity, ymax = mean_severity + sd_severity, width = 0.01))+\n    geom_line()\n```\n\n::: {.cell-output-display}\n![](Aula15_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\n  curve3 <- curve |>\n    group_by(Irrigation, rep) |>\n    summarise(audpc = AUDPC(day, severity, \n                            y_proportion = F)) |>\n    pivot_wider(1, names_from = Irrigation,\n              values_from = audpc)\n  \n  t.test(curve3$Drip, curve$Furrow)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  curve3$Drip\nt = 51.206, df = 2, p-value = 0.0003812\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 12.26473 14.51493\nsample estimates:\nmean of x \n 13.38983 \n```\n:::\n:::\n\n\n# Exercício prático:\n\n-   Carregando o conjunto de dados, mutando a variável lesion size de categórica para numerica, agrupando as variáveis e resumindo os dados:\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-8_d1b5ab8f66c11bcb0edd6da86bf64cd2'}\n\n```{.r .cell-code}\nlesion_size <- read_excel(\"tan-spot-wheat.xlsx\", \"lesion_size\")\n\nlesion2 <- lesion_size |>\nmutate(lesion_size = as.numeric(lesion_size)) |>\ngroup_by(cult, silicio, hai) |>\nsummarise(mean_lesion = mean(lesion_size), sd_lesion = sd(lesion_size))\n```\n:::\n\n\nVisualizando os dados graficamente:\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-9_9ea31d2a68529e1b36624dcf3b2b69cf'}\n\n```{.r .cell-code}\nlesion2 |>\n  ggplot(aes(hai, mean_lesion, color = silicio))+\n  geom_line()+\n  geom_point()+\n    geom_errorbar(aes(ymin = mean_lesion - sd_lesion, \n                     ymax = mean_lesion + sd_lesion), \n                     width = 0.01)+\n    facet_wrap(~cult)+\n  labs(y = \"Lesion size (mm)\",\n       x = \"Hours after inoculation (hai)\", color = \"Treatment\")\n```\n\n::: {.cell-output-display}\n![](Aula15_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n# Análise de área abaixo da curva de progresso da doença - AUDPC\n\nA AUDPC (Area Under the Disease Progress Curve) é uma medida utilizada na fitopatologia para quantificar e comparar o progresso de doenças em plantas ao longo do tempo.\n\nA AUDPC é calculada pelos dados de observações repetidas do tamanho ou severidade da lesão em diferentes momentos. A curva do progresso da doença é plotada com o tempo no eixo x e a variável de interesse (ex. tamanho da lesão) no eixo y. A área abaixo dessa curva é então calculada para determinar AUDPC. Valores mais altos de AUDPC indicam um maior impacto da doença, enquanto valores mais baixos indicam um impacto menor.\n\n**Aplicando a AUDPC e visualizando em boxplot**: Nesse bloco de comandos, calculamos a AUDPC para o tamanho da lesão com base nas informações de lesion_size, hai e nos grupos definidos pelas variáveis exp, cult, silicio e rep.\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-10_23e025c58a8993aa35f927ea36a7cde0'}\n\n```{.r .cell-code}\nlesion3 <- lesion_size |>\n  mutate(lesion_size = as.numeric(lesion_size)) |>\n  group_by(exp, cult, silicio, rep) |>\n  summarise(audpc = AUDPC(lesion_size, hai))\n\nlesion3 |>\n  ggplot(aes(cult, audpc, color = silicio))+\n  geom_boxplot()+\n  facet_wrap(~ exp)\n```\n\n::: {.cell-output-display}\n![](Aula15_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nFunção summarise(audpc = AUDPC(lesion_size, hai)): usamos a função summarise para calcular a AUDPC usando a função AUDPC() com as variáveis lesion_size e hai. O resultado é armazenado na nova variável audpc.\n\n## Teste ANOVA\n\nOs resultados da análise de variância podem ajudar a identificar quais variáveis e interações têm efeito significativo na variável resposta audpc.\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-11_a4ef55217ed0211d1e18f9dbbfc51f46'}\n\n```{.r .cell-code}\naov1<- aov(audpc ~ exp*cult*silicio, data = lesion3)\nsummary(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Df  Sum Sq Mean Sq F value   Pr(>F)    \nexp               1   54544   54544   0.533 0.470257    \ncult              1  751290  751290   7.335 0.010281 *  \nsilicio           1 9051552 9051552  88.377 3.15e-11 ***\nexp:cult          1   36717   36717   0.359 0.553089    \nexp:silicio       1      49      49   0.000 0.982615    \ncult:silicio      1 1412562 1412562  13.792 0.000689 ***\nexp:cult:silicio  1  143643  143643   1.403 0.244065    \nResiduals        36 3687093  102419                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nSe não der significativo, reduz o modelo:\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-12_2fcd4e17b712d8ab94d179ccf18a1589'}\n\n```{.r .cell-code}\naov1<- aov(audpc ~ cult*silicio, data = lesion3)\nsummary(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Df  Sum Sq Mean Sq F value   Pr(>F)    \ncult          1  751290  751290   7.662  0.00850 ** \nsilicio       1 9051552 9051552  92.315 6.04e-12 ***\ncult:silicio  1 1412562 1412562  14.406  0.00049 ***\nResiduals    40 3922047   98051                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nPara ver se o modelo está correto, checa as *premissas*.\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-13_87b5ee5ab8b7d1a31f19a0b791a4cde1'}\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Non-normality of residuals detected (p = 0.003).\n```\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.040).\n```\n:::\n:::\n\n\nSe não atende as premissas, *transforma os dados* e verifica as médias:\n\n\n::: {.cell hash='Aula15_cache/html/unnamed-chunk-14_8fd94184d4e991bbe258eb84dbd64c8e'}\n\n```{.r .cell-code}\naov1<- aov(sqrt(audpc) ~ cult*silicio, data = lesion3)\nsummary(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Df Sum Sq Mean Sq F value   Pr(>F)    \ncult          1  294.0   294.0   13.51 0.000712 ***\nsilicio       1 2363.9  2363.9  108.65 7.81e-13 ***\ncult:silicio  1  526.5   526.5   24.20 1.62e-05 ***\nResiduals    39  848.6    21.8                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n1 observation deleted due to missingness\n```\n:::\n\n```{.r .cell-code}\ncheck_normality(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: residuals appear as normally distributed (p = 0.146).\n```\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Error variance appears to be homoscedastic (p = 0.638).\n```\n:::\n\n```{.r .cell-code}\nlibrary(emmeans)\n\nm1 <- emmeans(aov1, ~ cult | silicio, type = \"response\")\nm1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsilicio = Si-:\n cult      response    SE df lower.CL upper.CL\n Horizonte     1440 106.8 39     1233     1664\n Quartzo       1537 110.3 39     1322     1768\n\nsilicio = Si+:\n cult      response    SE df lower.CL upper.CL\n Horizonte      897  84.2 39      735     1075\n Quartzo        296  50.7 39      202      407\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}