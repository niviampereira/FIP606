{"title":"Análises estatísticas","markdown":{"yaml":{"title":"Análises estatísticas","author":"Nívia","format":"html"},"headingText":"Tipos de testes para análise estatística","containsRefs":false,"markdown":"\n\n\nVeremos nesta aula os tipos de análise de acordo com o número e tipo de variáveis independentes (níveis do fator) e também o número de tratamentos ou grupos a serem comparados.\n\n## Teste T\n\nO teste t compara DUAS MÉDIAS (2 tratamentos) e mostra se as diferenças entre essas médias são significativas. Como todo teste estatístico, o teste t também tem como produto a medida do valor de p. Ou seja, no final das contas, teremos calculado a probabilidade da diferença encontrada (entre as médias) terem sido por acaso. Existem 2 tipos mais comuns de teste t:\n\n-   teste t para 2 amostras **dependentes** (ou pareadas): compara as médias da [mesma população]{.underline} em diferentes momentos de tempo (ex.: antes e depois).\n\n-   teste t para 2 amostras **independentes** (ou não pareadas): compara as médias de [duas populações distintas]{.underline}.\n\nOs termos paramétrico e não-paramétrico referem-se à média e ao desvio-padrão, que são os parâmetros que definem as populações que apresentam distribuição normal. Veremos como trabalahar nessas duas diferentes sutuações.\n\n### Dois tratamentos independentes\n\n*Situação*:Um pesquisador conduziu um experimento com o objetivo de avaliar o efeito de um micronutriente, o magnésio (Mg), adicionado na solução do solo cultivado com plantas de arroz, no manejo de uma doença fúngica. O experimento foi conduzido em delineamento inteiramente casualizado com 10 repetições, sendo cada repetição um vaso de planta. Um dos tratamentos é o chamado controle, ou testemunha, sem o suplemento mineral. O segundo é aquele com o suplemento do Mg na dose de 2 mM. Em cada uma das repetições foi obtido um valor médio do comprimento de lesões em um determinado tempo após a inoculação.\n\n**Preparo pré-análise**: carregamento de pacotes e importação do conjunto de dados.\n\n```{r}\n#| warning: false\n#| message: false\nlibrary(magrittr) # para usar pipes\nlibrary(ggplot2) # para gráficos\nlibrary(dplyr)\nlibrary(readxl)\nlibrary(tidyr)\n```\n\n```{r}\ndata_mg <- read_excel(\"dados-diversos.xlsx\")\nhead(data_mg)\n```\n\nAgora, vamos começar a trabalhar esses dados e obter estatísticas que descrevem o conjunto de dados, seja a tendência central ou a dispersão dos dados. Neste caso, trabalhamos com a média (mean), variância (var), desvio padrão (sd), erro padrão (se) e intervalo de confiança (ci). O intervalo de confiança é apenas para inferência visual.\n\n```{r}\ndata2 <- data_mg %>%\n  group_by(trat) %>%\n  summarise(\n    mean_com = mean(comp),\n    sd_comp = sd(comp),\n    var_comp = var(comp),\n    n = n(),\n    se_comp = sd_comp / sqrt(n - 1),\n    ci = se_comp * qt(0,025, df = 9))\ndata2\n```\n\n**Visualização**: A maneira mais simples é visualizar, no caso de mais de 6 repetições, usando boxplots juntamente com os dados de cada repetição. Aqui visualizaremos os dados em gráfico de barras vertical com erro padrão.\n\n```{r}\ndata2 |> \n  ggplot(aes(trat, mean_com)) +\n  geom_col(width = 0.5,\n           fill = \"steelblue\") +\n  geom_errorbar(aes(\n    ymin = mean_com - se_comp,\n    ymax = mean_com + se_comp),\n    width = 0.1) +\n  ylim(0,20) +\nlabs(x = \"\", y = \"Mean size (mm)\")\n```\n\n*Intervalo de confiança*: Agora visualizamos os dados com o ci. Abaixo, as barras verticais representam o intervalo de confiança 95%.\n\n```{r}\ndata2 |> \n  ggplot(aes(trat, mean_com)) +\n  geom_col(width = 0.5, fill = \"steelblue\") +\n  geom_errorbar(aes(\n    ymin = mean_com - ci,\n    ymax = mean_com + ci),\n    width = 0.1) +\n  ylim(0,20) +\nlabs(x = \"\", y = \"Mean size (mm)\")\n```\n\nO conjunto de dados está no formato largo, assim a variável resposta de interesse está apenas em uma coluna. Existem várias formas de separar em dois vetores os dados de resposta para cada tratamento. Uma delas é por meio da função pivot_winder, a qual coloca as respostas em duas colunas, uma para cada tratamento. Para isso, criaremos o conjunto data_mg2. Agora é posspivel visualizar as respostas (tamanho da lesão) para cada tratamento usando o conjunto de dados original, já que O ggplot2 requer os dados no formato largo.\n\n```{r}\ndata_mg2 <- data_mg |>\n  pivot_wider(1,\n              names_from = trat,\n              values_from = comp)\ndata_mg2\n```\n\n#### Teste de hipótese - teste t\n\nTeste t é um teste paramétrico e para ele precisa seguir 2 premissas - normalidade e homogeneidade da variância (homocedasticidade). Caso hja necessidade de transformação dos dados para deixá-los normais, é aceitável.\n\n```{r}\nt.test(data_mg2$Mg2, data_mg2$control, \npaired = F)\n```\n\nA ordem de execução dos testes deve ser: Shapiro.teste (teste de normalidade) \\> var.test (teste de homocedasticidade) \\> se p menor que 0,05 \\> t.test. No caso da variância dar heterogênea, var EQUAL = F. No caso dos dados pareados usa-se o argumento pared = TRUE\n\n##### Homocedastididade\n\nPodemos confirmar a premissa da homocedasticidade pelo teste F. No caso de dois grupos, a função que pode ser usada é a var.test do R. Vamos usar o formato largo e chamar os dois vetores do conjunto. Verifique o P-valor na saída da análise.\n\n```{r}\nattach(data_mg2)\nvar.test(Mg2, control)\n```\n\nA verificação deste pressuposto também pode ser realizada graficamente através do boxplot para os tratamentos vs resíduos. Se existir homocedasticidade espera-se que os boxplots sejam semelhantes.\n\n##### Normalidade\n\nA normalidade pode ser testada por meio de procedimentos visuais e testes específicos. Para testar a normalidade dos dados, fazemos o teste shapiro.\n\n```{r}\nshapiro.test(Mg2)\nshapiro.test(control)\n```\n\n**Análise visual da premissa de normalidade**: A análise visual da premissa de normalidade é realizada por qqplot (QQ-Plot), que permite verificar se uma amostra segue uma distribuição gaussiana. Podemos simplesmente fazer usando as funções qqnorm() e qqline() para cada umas das variáveis analisadas.\n\n```{r}\nqqnorm (Mg2)\nqqline(Mg2)\nqqnorm(control)\nqqline(control)\n```\n\n### Dois tratamentos dependentes\n\nSe as premissas de normalidade não fossem atendidas, qual o teste que poderia ser usado? Nesse caso de dois grupos há duas possibilidades, uma é usar um teste não paramétrico ou um teste baseado em reamostragem (bootstrapping) dos dados, os quais independem do modelo de distribuição. Vejamos um exemplo.\n\n*Situação*: Um experimento foi conduzido para avaliar o efeito do uso da escala na acurácia e precisão de avaliações visuais de severidade por avaliadores. A hipótese a ser testada foi que avaliações utilizando uma escala digramática como auxílio são mais acuradas do que sem o uso do auxílio. Dez avaliadores foram escolhidos aleatoriamente e fizeram duas avaliações cada. Cinco variáveis que compõe a medida da concordância das estimativas foram obtidas. Uma vez que as medidas foram repetidas no tempo para cada avaliador, as amostras são do tipo dependentes.\n\n**Preparo pré-análise**: importação dos dados e preparo do conjunto.\n\n```{r}\nescala <- read_excel(\"dados-diversos.xlsx\", \"escala\")\nhead(escala)\n\nescala2 <- escala |> \n  select(assessment, rater, acuracia)\nescala3 <- escala2|>\n  pivot_wider(1,\n              names_from = assessment,\n              values_from = acuracia)\n\n```\n\n**Checagem das premissas**:\n\n```{r}\n## homocedasticidade dois grupos\nattach(escala3)\nvar.test(Aided1, Unaided)\n\n## normalidade\nshapiro.test(Aided1)$p.value\nshapiro.test(Unaided)$p.value\n```\n\n*Análise visual da normalidade*:\n\n```{r}\nqqnorm(Aided1)\nqqline(Aided1)\nqqnorm(Unaided)\nqqline(Unaided)\n```\n\n### Teste T paramétrico\n\n```{r}\n## teste t para amostras pareadas\nt_escala <- t.test(escala3$Aided1, escala3$Unaided,\n  paired = TRUE,\n  var.equal = F\n)\n\nt_escala\n```\n\n### Teste para dados não paramétricos\n\nUm teste não paramétrico não faz nenhuma suposição sobre a distribuição da população ou tamanho da amostra. O Wilcox.test é o teste para dados não paramétricos equivalente ao teste t para dados paramétricos. o teste de Wilcoxon é usado para testar se as medianas das amostras são iguais nos casos em que a suposição de normalidade não é satisfeita ou quando não for possível checar essa suposição.\n\n```{r}\nwilcox.test(escala3$Aided1, escala3$Unaided, paired = TRUE)\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"Aula9.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","fontsize":"1.1em","theme":{"light":"flatly","dark":"darkly"},"title":"Análises estatísticas","author":"Nívia"},"extensions":{"book":{"multiFile":true}}}}}